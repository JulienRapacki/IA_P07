{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNzVB212iGbgiagGqQbgWzk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#PROJET 7\n","##API classification de sentiment"],"metadata":{"id":"I4Zrv8zje3eB"}},{"cell_type":"code","source":["!pip install pyngrok --quiet\n","!pip install Flask pyngrok --quiet"],"metadata":{"id":"XLwbZSKfsUzS","executionInfo":{"status":"ok","timestamp":1719493389877,"user_tz":-120,"elapsed":20229,"user":{"displayName":"Julien Rapacki","userId":"09152015285274349547"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import time\n","import re\n","\n","import pickle\n","\n","# pre-traitement du text\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import SnowballStemmer\n","\n","# pour le modèle simple\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","    # pour le modèle LSTM\n","\n","# Deep learning\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SDi5BQKkv8Ei","executionInfo":{"status":"ok","timestamp":1719493402356,"user_tz":-120,"elapsed":12482,"user":{"displayName":"Julien Rapacki","userId":"09152015285274349547"}},"outputId":"c5c7f921-4ec3-4955-c503-1e637dbdecee"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# téléchargement des bases de caractères\n","nltk.download(\"stopwords\")\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","stop = set(stopwords.words('english'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wy7h71Ajv78E","executionInfo":{"status":"ok","timestamp":1719493402356,"user_tz":-120,"elapsed":5,"user":{"displayName":"Julien Rapacki","userId":"09152015285274349547"}},"outputId":"a164e84a-6454-4f8a-9313-89cb312d1ae0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}]},{"cell_type":"code","source":["# regex permettant d'ignorer les caractères spéciaux ainsi que les nombres et les mots contenant des underscores\n","\n","def preprocess(text) :\n","\n","    def tokenize(text):\n","        tokenizer = nltk.RegexpTokenizer(r'\\b(?![\\w_]*_)[^\\d\\W]+\\b')\n","        # Tokenisation de la description et suppression des majuscules\n","        tokens = tokenizer.tokenize(text.lower())\n","        return tokens\n","\n","    def lemmatize_word(text):\n","\n","        lemmatizer = WordNetLemmatizer()\n","        lemma = [lemmatizer.lemmatize(token) for token in text]\n","        return lemma\n","\n","    def combine_text(list_of_text):\n","\n","        combined_text = ' '.join(list_of_text)\n","        return combined_text\n","\n","    token = tokenize(text)\n","    stop_removed = [token for token in token if token not in stop]\n","    lemma = lemmatize_word(stop_removed)\n","    combined = combine_text(lemma)\n","\n","    return  combined"],"metadata":{"id":"wbF7KJgzwGgf","executionInfo":{"status":"ok","timestamp":1719493402356,"user_tz":-120,"elapsed":4,"user":{"displayName":"Julien Rapacki","userId":"09152015285274349547"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["MAX_SEQUENCE_LENGTH =30\n"],"metadata":{"id":"hcq-wvKAwJIy","executionInfo":{"status":"ok","timestamp":1719493402356,"user_tz":-120,"elapsed":3,"user":{"displayName":"Julien Rapacki","userId":"09152015285274349547"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Chargement du tokenizer préalablement entraîné\n","with open(\"/content/drive/MyDrive/Colab Notebooks/PROJET07/P07_github/tokenizer_lstm.pickle\", \"rb\") as file:\n","    tokenizer = pickle.load(file)\n","\n","\n","\n","def predict_sentiment(text):\n","\n","        # First let's preprocess the text in the same way than for the training\n","        text = preprocess(text)\n","\n","        # Let's get the index sequences from the tokenizer\n","        index_sequence = pad_sequences(tokenizer.texts_to_sequences([text]),\n","                                    maxlen = MAX_SEQUENCE_LENGTH)\n","\n","        probability_score = clf_model.predict(index_sequence)[0][0]\n","\n","        # Compte-tenu  du résultat de la courbe ROC-AUC, on préfèrera mettre un seuil à 0.6\n","        # pour la proba afin de limiter les faux positifs\n","        if probability_score < 0.6:\n","            sentiment = \"negative\"\n","        else:\n","            sentiment = \"positive\"\n","\n","        return sentiment, probability_score\n","\n","\n","clf_model = load_model('/content/drive/MyDrive/Colab Notebooks/PROJET07/P07_github/model_lstm_glove.h5')"],"metadata":{"id":"4Jv-fru3wMlQ","executionInfo":{"status":"ok","timestamp":1719493404143,"user_tz":-120,"elapsed":1790,"user":{"displayName":"Julien Rapacki","userId":"09152015285274349547"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["ngrok.kill()"],"metadata":{"id":"YR_vKZvCstxB","executionInfo":{"status":"ok","timestamp":1719494422966,"user_tz":-120,"elapsed":304,"user":{"displayName":"Julien Rapacki","userId":"09152015285274349547"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["from flask import Flask, request, jsonify\n","\n","app = Flask(__name__)\n","\n","@app.route(\"/\")\n","def home():\n","    return \"Hello, welcome on the sentiment classification API project 07!\"\n","\n","\n","@app.route('/predict_sentiment', methods=['POST'])\n","def predict():\n","    data = request.json\n","\n","    #insertion du modèle\n","    text = request.args['text']\n","\n","    results = predict_sentiment(text)\n","\n","    return jsonify(text=text, sentiment=results[0], probability=str(results[1]))\n","from threading import Thread\n","\n","def run_flask():\n","    app.run(port=5000)\n","\n","flask_thread = Thread(target=run_flask)\n","flask_thread.start()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LDW3-p9HsUuT","executionInfo":{"status":"ok","timestamp":1719494427628,"user_tz":-120,"elapsed":391,"user":{"displayName":"Julien Rapacki","userId":"09152015285274349547"}},"outputId":"6918685d-9c9a-4a1d-fa1b-3e4bb8fb4a2a"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":[" * Serving Flask app '__main__'\n"," * Debug mode: off\n","Public URL: NgrokTunnel: \"https://0993-34-145-225-145.ngrok-free.app\" -> \"http://localhost:5000\"\n"]},{"output_type":"stream","name":"stderr","text":["Address already in use\n","Port 5000 is in use by another program. Either identify and stop that program, or start the server with a different port.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"o1Gl0p1aykDM"},"execution_count":null,"outputs":[]}]}