{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNUTAB2LjZjruytih4s+/Ph"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#PROJET 7\n","##API classification de sentiment"],"metadata":{"id":"I4Zrv8zje3eB"}},{"cell_type":"code","source":["!pip install pyngrok --quiet\n","!pip install Flask pyngrok --quiet"],"metadata":{"id":"XLwbZSKfsUzS","executionInfo":{"status":"ok","timestamp":1719499199445,"user_tz":-120,"elapsed":15708,"user":{"displayName":"Julien Rapacki","userId":"09152015285274349547"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import time\n","import re\n","\n","import pickle\n","\n","# pre-traitement du text\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import SnowballStemmer\n","\n","# pour le modèle simple\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","    # pour le modèle LSTM\n","\n","# Deep learning\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SDi5BQKkv8Ei","executionInfo":{"status":"ok","timestamp":1719499201497,"user_tz":-120,"elapsed":2055,"user":{"displayName":"Julien Rapacki","userId":"09152015285274349547"}},"outputId":"6f25c748-3b79-4102-8cdd-e35ddbf7c9b1"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# téléchargement des bases de caractères\n","nltk.download(\"stopwords\")\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","stop = set(stopwords.words('english'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wy7h71Ajv78E","executionInfo":{"status":"ok","timestamp":1719499201497,"user_tz":-120,"elapsed":4,"user":{"displayName":"Julien Rapacki","userId":"09152015285274349547"}},"outputId":"cf041e8f-2528-4310-8b0d-23fd10a5bd82"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}]},{"cell_type":"code","source":["# regex permettant d'ignorer les caractères spéciaux ainsi que les nombres et les mots contenant des underscores\n","\n","def preprocess(text) :\n","\n","    def tokenize(text):\n","        tokenizer = nltk.RegexpTokenizer(r'\\b(?![\\w_]*_)[^\\d\\W]+\\b')\n","        # Tokenisation de la description et suppression des majuscules\n","        tokens = tokenizer.tokenize(text.lower())\n","        return tokens\n","\n","    def lemmatize_word(text):\n","\n","        lemmatizer = WordNetLemmatizer()\n","        lemma = [lemmatizer.lemmatize(token) for token in text]\n","        return lemma\n","\n","    def combine_text(list_of_text):\n","\n","        combined_text = ' '.join(list_of_text)\n","        return combined_text\n","\n","    token = tokenize(text)\n","    stop_removed = [token for token in token if token not in stop]\n","    lemma = lemmatize_word(stop_removed)\n","    combined = combine_text(lemma)\n","\n","    return  combined"],"metadata":{"id":"wbF7KJgzwGgf","executionInfo":{"status":"ok","timestamp":1719499201498,"user_tz":-120,"elapsed":3,"user":{"displayName":"Julien Rapacki","userId":"09152015285274349547"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["MAX_SEQUENCE_LENGTH =30\n"],"metadata":{"id":"hcq-wvKAwJIy","executionInfo":{"status":"ok","timestamp":1719499220530,"user_tz":-120,"elapsed":292,"user":{"displayName":"Julien Rapacki","userId":"09152015285274349547"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["# Chargement du tokenizer préalablement entraîné\n","with open(\"./tokenizer_lstm.pickle\", \"rb\") as file:\n","    tokenizer = pickle.load(file)\n","\n","\n","\n","def predict_sentiment(text):\n","\n","        # First let's preprocess the text in the same way than for the training\n","        text = preprocess(text)\n","\n","        # Let's get the index sequences from the tokenizer\n","        index_sequence = pad_sequences(tokenizer.texts_to_sequences([text]),\n","                                    maxlen = MAX_SEQUENCE_LENGTH)\n","\n","        probability_score = clf_model.predict(index_sequence)[0][0]\n","\n","        # Compte-tenu  du résultat de la courbe ROC-AUC, on préfèrera mettre un seuil à 0.6\n","        # pour la proba afin de limiter les faux positifs\n","        if probability_score < 0.6:\n","            sentiment = \"negative\"\n","        else:\n","            sentiment = \"positive\"\n","\n","        return sentiment, probability_score\n","\n","\n","clf_model = load_model('./model_lstm_glove.h5')"],"metadata":{"id":"4Jv-fru3wMlQ","executionInfo":{"status":"error","timestamp":1719499222192,"user_tz":-120,"elapsed":333,"user":{"displayName":"Julien Rapacki","userId":"09152015285274349547"}},"colab":{"base_uri":"https://localhost:8080/","height":211},"outputId":"a577efc2-248a-4851-9902-78deb5d4bc78"},"execution_count":37,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: './tokenizer_lstm.pickle'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-301eb34b404d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Chargement du tokenizer préalablement entraîné\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./tokenizer_lstm.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './tokenizer_lstm.pickle'"]}]},{"cell_type":"code","source":["ngrok.kill()"],"metadata":{"id":"YR_vKZvCstxB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from flask import Flask, request, jsonify\n","\n","app = Flask(__name__)\n","\n","@app.route(\"/\")\n","def home():\n","    return \"Hello, welcome on the sentiment classification API project 07!\"\n","\n","\n","@app.route('/predict_sentiment', methods=['POST'])\n","def predict():\n","    data = request.json\n","\n","    #insertion du modèle\n","    text = request.args['text']\n","\n","    results = predict_sentiment(text)\n","\n","    return jsonify(text=text, sentiment=results[0], probability=str(results[1]))\n","from threading import Thread\n","\n","def run_flask():\n","    app.run(port=5000)\n","\n","flask_thread = Thread(target=run_flask)\n","flask_thread.start()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LDW3-p9HsUuT","executionInfo":{"status":"ok","timestamp":1719494427628,"user_tz":-120,"elapsed":391,"user":{"displayName":"Julien Rapacki","userId":"09152015285274349547"}},"outputId":"6918685d-9c9a-4a1d-fa1b-3e4bb8fb4a2a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" * Serving Flask app '__main__'\n"," * Debug mode: off\n","Public URL: NgrokTunnel: \"https://0993-34-145-225-145.ngrok-free.app\" -> \"http://localhost:5000\"\n"]},{"output_type":"stream","name":"stderr","text":["Address already in use\n","Port 5000 is in use by another program. Either identify and stop that program, or start the server with a different port.\n"]}]},{"cell_type":"code","source":["# Générer le fichier requirements.txt\n","!pip freeze > requirements.txt\n","\n","# Télécharger le fichier requirements.txt\n","from google.colab import files\n","files.download('requirements.txt')"],"metadata":{"id":"o1Gl0p1aykDM","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1719499230913,"user_tz":-120,"elapsed":2015,"user":{"displayName":"Julien Rapacki","userId":"09152015285274349547"}},"outputId":"6e3ae68a-ced6-4fe0-ff3f-6c15fe568f9c"},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_912467fe-92f9-4ab5-a912-d8efd1c51bca\", \"requirements.txt\", 10509)"]},"metadata":{}}]}]}